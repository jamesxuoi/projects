{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_json(\"Electronics_5.json\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[[\"reviewText\",\"overall\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns = [\"Reviews\",\"Rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Amazon_Unlocked_Mobile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Reviews\",\"Rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 1892669 training examples and 210297 validation examples. \n",
      "\n",
      "Show a review in the training set : \n",
      " This thing pretty much covers all the bases as an AC adapter.  Especially nice is the inclusion of the USB port, and the reversibility of the polarity to the plugs.  But what were they thinking with this collection of plugs?  They're attached to a rubber strip which is attached to... NOTHING.  All the plugs other than the one you're using WILL get lost, and probably quickly.There's a baffling little pincer of rubber at the top of the plug strip that doesn't attach to anything securely, including the wire.  It's so dumb that it's infuriating.  They should have had a slot down the side of the adapter to hold the plugs.\n"
     ]
    }
   ],
   "source": [
    "# Split data into training set and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Reviews'], df['Rating'], \\\n",
    "                                                    test_size=0.1, random_state=0)\n",
    "\n",
    "print('Load %d training examples and %d validation examples. \\n' %(X_train.shape[0],X_test.shape[0]))\n",
    "print('Show a review in the training set : \\n', X_train.iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(raw_text, remove_stopwords=False, stemming=False, split_text=False, \\\n",
    "             ):\n",
    "    '''\n",
    "    Convert a raw review to a cleaned review\n",
    "    '''\n",
    "    text = BeautifulSoup(raw_text, 'lxml').get_text()  #remove html\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)  # remove non-character\n",
    "    words = letters_only.lower().split() # convert to lower case \n",
    "    \n",
    "    if remove_stopwords: # remove stopword\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "        \n",
    "    if stemming==True: # stemming\n",
    "#         stemmer = PorterStemmer()\n",
    "        stemmer = SnowballStemmer('english') \n",
    "        words = [stemmer.stem(w) for w in words]\n",
    "        \n",
    "    if split_text==True:  # split text\n",
    "        return (words)\n",
    "    \n",
    "    return( \" \".join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00K15KRV6/ref=cm_cr_ryp_prd_ttl_sol_22\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B013YDFH3Y?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00QF5QJR2/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/gp/product/B00JEMZYM4/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00YD547Q6/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B013YDFH3Y?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00K15KRV6/ref=cm_cr_ryp_prd_ttl_sol_22\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00QF5QJR2/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B01CJU9BBM/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B00EZHM9JE?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00K15KRV6/ref=cm_cr_ryp_prd_ttl_sol_22\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B013YDFH3Y?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00YD547Q6/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B0193D539M?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://smile.amazon.com/gp/product/B00VTTB5C8/ref=cm_cr_ryp_prd_ttl_sol_1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B00PEJQU9M?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B01CJU9BBM/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00QF5QJR2/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00QF5QJR2/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/gp/product/B00G197Q4M/ref=cm_cr_ryp_prd_ttl_sol_26\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00K15KRV6/ref=cm_cr_ryp_prd_ttl_sol_22\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B01CJU9BBM/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/gp/product/B00U8KSNB0/ref=cm_cr_ryp_prd_ttl_sol_22\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B013YDFH3Y?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B01CJU9BBM/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/gp/product/B00JEMZYM4/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B013YDFH3Y?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B013YDFH3Y?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00YD547Q6/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00YD547Q6/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B01CJU9BBM/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B013YDFH3Y?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/Sony-Xperia-C5-Ultra-Unlocked/dp/B016AM1S2A/ref=cm_cr_arp_d_product_top?ie=UTF8\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B013YDFH3Y?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B013YDFH3Y?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B0193D539M?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00K15KRV6/ref=cm_cr_ryp_prd_ttl_sol_22\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/gp/product/B00JFNDLRC/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B013YDFH3Y?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/gp/product/B00U8KSNB0/ref=cm_cr_ryp_prd_ttl_sol_22\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B013YDFH3Y?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00YD547Q6/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00QF5QJR2/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B01BO6BYMQ/ref=cm_cr_ryp_prd_ttl_sol_1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B013YDFH3Y?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://adskpak.com/?type=2&id=darf85&sid=11449\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B00OSTKZWM?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B00PEJQU9M?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B01CJU9BBM/ref=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show a cleaned review in the training set : \n",
      " this thing pretty much covers all the bases as an ac adapter especially nice is the inclusion of the usb port and the reversibility of the polarity to the plugs but what were they thinking with this collection of plugs they re attached to a rubber strip which is attached to nothing all the plugs other than the one you re using will get lost and probably quickly there s a baffling little pincer of rubber at the top of the plug strip that doesn t attach to anything securely including the wire it s so dumb that it s infuriating they should have had a slot down the side of the adapter to hold the plugs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.amazon.com/dp/B00K15KRV6/ref=cm_cr_ryp_prd_ttl_sol_22\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B013YDFH3Y?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/duypt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/B013YDFH3Y?redirect=true&ref_=cm_cr_ryp_prd_ttl_sol_0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "# Preprocess text data in training set and validation set\n",
    "X_train_cleaned = []\n",
    "X_test_cleaned = []\n",
    "\n",
    "for d in X_train:\n",
    "    X_train_cleaned.append(cleanText(d))\n",
    "print('Show a cleaned review in the training set : \\n',  X_train_cleaned[10])\n",
    "    \n",
    "for d in X_test:\n",
    "    X_test_cleaned.append(cleanText(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = [0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features : 76760 \n",
      "\n",
      "Show some feature names : \n",
      " ['aa', 'ading', 'alligators', 'anticipates', 'aspecto', 'awide', 'beanbags', 'blankenshipthe', 'braille', 'buys', 'carto', 'chesapeake', 'clutter', 'compressable', 'conversed', 'crookedly', 'dcb', 'descriptioni', 'disapearing', 'doodad', 'dxva', 'emitters', 'espon', 'expressway', 'ferocious', 'flowy', 'fruity', 'getaways', 'graphgrip', 'handsfree', 'hess', 'huddle', 'implosion', 'insiders', 'irreplaceable', 'journalist', 'kokak', 'letdowns', 'loner', 'manchester', 'melodious', 'misgiving', 'mourn', 'nas', 'nofull', 'offas', 'oscillates', 'panasonic', 'performancevery', 'pixilating', 'possess', 'probarla', 'pulpit', 'ramdomly', 'reconfirmed', 'reparation', 'rhinoskin', 'sacked', 'scrool', 'shapeless', 'sinusoidal', 'snares', 'specialist', 'starsbut', 'sua', 'sweatshop', 'telecoms', 'thetop', 'tofigure', 'trice', 'ultraslim', 'unpluged', 'vallarta', 'vlz', 'webtop', 'witholympus', 'xsi']\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform the training data to a document-term matrix using TfidfVectorizer \n",
    "tfidf = TfidfVectorizer(min_df=5) #minimum document frequency of 5\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_cleaned)\n",
    "print(\"Number of features : %d \\n\" %len(tfidf.get_feature_names())) #1722\n",
    "print(\"Show some feature names : \\n\", tfidf.get_feature_names()[::1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "# RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def modelEvaluation(predictions):\n",
    "    '''\n",
    "    Print model evaluation to predicted result \n",
    "    '''\n",
    "    print (\"\\nAccuracy on validation set: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "    print(\"\\nClassification report : \\n\", metrics.classification_report(y_test, predictions))\n",
    "    print(\"\\nConfusion Matrix : \\n\", metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on validation set: 0.6566\n",
      "\n",
      "Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.47      0.57     18036\n",
      "          2       0.69      0.18      0.29     10708\n",
      "          3       0.56      0.17      0.26     17637\n",
      "          4       0.45      0.24      0.31     40835\n",
      "          5       0.68      0.93      0.79    123081\n",
      "\n",
      "avg / total       0.63      0.66      0.61    210297\n",
      "\n",
      "\n",
      "Confusion Matrix : \n",
      " [[  8402    316    422   1209   7687]\n",
      " [  1082   1963    418   1392   5853]\n",
      " [   783    201   3024   2857  10772]\n",
      " [   502    164    788   9734  29647]\n",
      " [   682    185    780   6477 114957]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the validaton set\n",
    "predictions = model.predict(tfidf.transform(X_test_cleaned))\n",
    "modelEvaluation(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'RF-amazon.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf, open('tfidf.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_train_cleaned, open('X_train_cleaned.sav', 'wb'))\n",
    "pickle.dump(X_test_cleaned, open('X_test_cleaned.sav', 'wb'))\n",
    "pickle.dump(y_train, open('y_train.sav', 'wb'))\n",
    "pickle.dump(y_test, open('y_test.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duy\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.19.1 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\duy\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.19.1 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\duy\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator TfidfVectorizer from version 0.19.1 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model = pickle.load(open('LR-amazon.sav', 'rb'))\n",
    "tfidf = pickle.load(open('tfidf.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\duy\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "da = model.predict_proba(tfidf.transform([cleanText(\"Alright, beautiful look and comforting fit DOES NOT excuse it quality wise. My Playstation's headset has better sound quality than these, the stereo sounds like something is blocking it like a hand, with high volume behind it and NO I don't have a defective model(just using a small example). It's just not as great as the reviews I was reading about it made it seem, I had HIGH expectations so I'm now disappointed in its outcome. This headset has absolutely RUINED my built in Mic headset experience, first hooking it up, the volume for the mic is SOOO LOW the pc could barely pick it up and my friends listening on the other end can't stand hearing me through it. This hands free mode bs has angered me to the point where I'm no longer buying built in microphone headsets, it ruins the sound quality of your pc's audio to boost the call/voice chat volume. It's entirely irritating, plus I don't know how to connect the headset via aux cable. normally with other products all i'd do is plug it in(while its connected to the headphones) using the aux chord & model BUT that does NOT work with this headset so, WHY IS THERE AN AUX CABLE?? Maybe I have to read the guide again, but all together I give it a two star, its not something too special to buy yourself if you're a producer like me looking for good quality headphones with a clear precise microphone for voice chats. I'll just use em for my phone, but other than that. I doubt it'll be helpful otherwise. Enjoy with caution.\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
